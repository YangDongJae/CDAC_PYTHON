{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File structure:\n",
      "Dataset: CAOfilter, Shape: (625, 625), Type: [('real', '<f8'), ('imag', '<f8')]\n",
      "\n",
      "Extracting data to DataFrames:\n",
      "  Error converting CAOfilter to DataFrame: Data must be 1-dimensional, got ndarray of shape (625, 625) instead\n",
      "No DataFrames were extracted.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def mat_to_dataframes(file_path):\n",
    "    \"\"\"\n",
    "    Extract data from MATLAB v7.3 file and convert suitable structures to DataFrames\n",
    "    \"\"\"\n",
    "    dataframes = {}  # Dictionary to store all extracted dataframes\n",
    "    \n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            # Print file structure first to understand what we're working with\n",
    "            print(\"File structure:\")\n",
    "            file.visititems(lambda name, obj: print(f\"{'Dataset' if isinstance(obj, h5py.Dataset) else 'Group'}: {name}, \"\n",
    "                                                   f\"{'Shape: ' + str(obj.shape) + ', Type: ' + str(obj.dtype) if isinstance(obj, h5py.Dataset) else ''}\"))\n",
    "            \n",
    "            # Process each top-level element\n",
    "            print(\"\\nExtracting data to DataFrames:\")\n",
    "            for key in file.keys():\n",
    "                # Check if it's a dataset directly\n",
    "                if isinstance(file[key], h5py.Dataset):\n",
    "                    df = dataset_to_dataframe(file[key], key)\n",
    "                    if df is not None:\n",
    "                        dataframes[key] = df\n",
    "                # If it's a group, try to extract structured data\n",
    "                else:\n",
    "                    group_dfs = extract_group_dataframes(file[key], parent_name=key)\n",
    "                    dataframes.update(group_dfs)\n",
    "                    \n",
    "            return dataframes\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return None\n",
    "\n",
    "def dataset_to_dataframe(dataset, name):\n",
    "    \"\"\"Convert an h5py dataset to a pandas DataFrame if possible\"\"\"\n",
    "    try:\n",
    "        data = dataset[()]\n",
    "        \n",
    "        # Handle string data\n",
    "        if data.dtype.kind in ('S', 'O', 'U'):\n",
    "            try:\n",
    "                # Try to convert character arrays to strings\n",
    "                if len(data.shape) == 2 and min(data.shape) == 1:\n",
    "                    data = ''.join(chr(c) for c in data.flat)\n",
    "                    print(f\"  Extracted string from {name}: {data}\")\n",
    "                    return None  # Single strings don't need a DataFrame\n",
    "            except:\n",
    "                pass  # If conversion fails, continue with normal processing\n",
    "        \n",
    "        # For 1D or 2D numeric arrays\n",
    "        if len(data.shape) <= 2:\n",
    "            # Convert to DataFrame (handles both 1D and 2D arrays)\n",
    "            df = pd.DataFrame(data)\n",
    "            print(f\"  Created DataFrame from {name}: {df.shape}\")\n",
    "            return df\n",
    "            \n",
    "        else:\n",
    "            print(f\"  Skipping {name}: {len(data.shape)}-dimensional data\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error converting {name} to DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_group_dataframes(group, parent_name=\"\"):\n",
    "    \"\"\"\n",
    "    Recursively extract DataFrames from group structure\n",
    "    Handles common MATLAB structure patterns in HDF5\n",
    "    \"\"\"\n",
    "    dataframes = {}\n",
    "    \n",
    "    # For each item in the group\n",
    "    for key in group.keys():\n",
    "        full_key = f\"{parent_name}/{key}\"\n",
    "        \n",
    "        # If it's a dataset, try to convert to DataFrame\n",
    "        if isinstance(group[key], h5py.Dataset):\n",
    "            df = dataset_to_dataframe(group[key], full_key)\n",
    "            if df is not None:\n",
    "                dataframes[full_key] = df\n",
    "        \n",
    "        # If it's a group, process recursively\n",
    "        else:\n",
    "            sub_dataframes = extract_group_dataframes(group[key], full_key)\n",
    "            dataframes.update(sub_dataframes)\n",
    "    \n",
    "    # Handle special case: MATLAB structure arrays\n",
    "    # These typically have fields like 'field1', 'field2' that should be combined\n",
    "    if all(k.startswith(parent_name + \"/\") for k in dataframes.keys()):\n",
    "        # Check if we can combine fields into a single DataFrame\n",
    "        try:\n",
    "            # Get all direct children fields\n",
    "            fields = [k.split('/')[-1] for k in dataframes.keys() \n",
    "                     if len(k.split('/')) == len(parent_name.split('/')) + 2]\n",
    "            \n",
    "            if fields:\n",
    "                print(f\"  Detected potential structure in {parent_name} with fields: {fields}\")\n",
    "                \n",
    "                # Future enhancement: combine structure fields into a single DataFrame\n",
    "                # This would require additional logic to align the data properly\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Main execution\n",
    "file_path = \"/home/work/OCT_DL/CDAC_OCT/CDAC_PYTHON/data/2_3Dregistration/d5_Int_05_CAO.mat\"\n",
    "all_dataframes = mat_to_dataframes(file_path)\n",
    "\n",
    "# Display summary of extracted DataFrames\n",
    "if all_dataframes:\n",
    "    print(\"\\nExtracted DataFrames Summary:\")\n",
    "    for name, df in all_dataframes.items():\n",
    "        print(f\"- {name}: Shape {df.shape}\")\n",
    "    \n",
    "    # Show the first DataFrame as an example\n",
    "    if len(all_dataframes) > 0:\n",
    "        first_key = list(all_dataframes.keys())[0]\n",
    "        print(f\"\\nFirst 5 rows of '{first_key}':\")\n",
    "        print(all_dataframes[first_key].head())\n",
    "else:\n",
    "    print(\"No DataFrames were extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert .mat into .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4 tensors to /home/work/OCT_DL/CDAC_OCT/CDAC_PYTHON/data/2_3Dregistration/d5_Int_08_subLayers_0704.pt\n",
      "- ILMnew: shape=(625, 625), dtype=torch.float64\n",
      "- ISOSnew: shape=(625, 625), dtype=torch.float64\n",
      "- NFLnew: shape=(625, 625), dtype=torch.float64\n",
      "- RPEnew: shape=(625, 625), dtype=torch.float64\n"
     ]
    }
   ],
   "source": [
    "# /scripts/convert_mat_v73_to_pt.py\n",
    "from __future__ import annotations\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "def _is_complex_struct(arr: np.ndarray) -> bool:\n",
    "    return hasattr(arr.dtype, \"names\") and arr.dtype.names is not None and {\"real\", \"imag\"} <= set(arr.dtype.names)\n",
    "\n",
    "def _to_numpy_numeric(ds: h5py.Dataset) -> np.ndarray | None:\n",
    "    \"\"\"h5py Dataset -> numpy numeric (float/complex). 비수치형은 None.\"\"\"\n",
    "    arr = ds[()]  # Load to numpy\n",
    "    # compound dtype (real/imag) → complex\n",
    "    if isinstance(arr, np.ndarray) and _is_complex_struct(arr):\n",
    "        arr = arr[\"real\"] + 1j * arr[\"imag\"]\n",
    "    # 문자열/객체 등 비수치형 스킵\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        return None\n",
    "    if arr.dtype.kind in (\"b\", \"i\", \"u\", \"f\", \"c\"):  # bool/int/uint/float/complex\n",
    "        return arr\n",
    "    return None\n",
    "\n",
    "def _walk_collect_numeric(f: h5py.File) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"파일 전체를 순회하며 수치형 dataset만 수집 (group 경로를 키로 사용).\"\"\"\n",
    "    out: Dict[str, np.ndarray] = {}\n",
    "    def visit(name: str, obj: Any):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            np_arr = _to_numpy_numeric(obj)\n",
    "            if np_arr is not None:\n",
    "                out[name] = np_arr\n",
    "    f.visititems(visit)\n",
    "    return out\n",
    "\n",
    "def convert_mat_v73_to_pt(mat_path: str | Path, out_pt_path: str | Path, keys: list[str] | None = None) -> dict:\n",
    "    \"\"\"v7.3 .mat → .pt(dict). keys가 None이면 모든 수치형 dataset 저장.\"\"\"\n",
    "    mat_path = str(mat_path)\n",
    "    tensors: Dict[str, torch.Tensor] = {}\n",
    "    with h5py.File(mat_path, \"r\") as f:\n",
    "        if keys is None:\n",
    "            np_dict = _walk_collect_numeric(f)\n",
    "        else:\n",
    "            np_dict = {}\n",
    "            for k in keys:\n",
    "                if k in f and isinstance(f[k], h5py.Dataset):\n",
    "                    arr = _to_numpy_numeric(f[k])\n",
    "                    if arr is not None:\n",
    "                        np_dict[k] = arr\n",
    "\n",
    "    for name, arr in np_dict.items():\n",
    "        # numpy → torch (복소 가능)\n",
    "        t = torch.from_numpy(arr)  # dtype 유지 (float64→torch.float64, complex128→torch.complex128)\n",
    "        tensors[name] = t\n",
    "\n",
    "    torch.save(tensors, str(out_pt_path))\n",
    "    return tensors\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    src = \"/home/work/OCT_DL/CDAC_OCT/CDAC_PYTHON/data/2_3Dregistration/d5_Int_08_subLayers_0704.mat\"\n",
    "    dst = \"/home/work/OCT_DL/CDAC_OCT/CDAC_PYTHON/data/2_3Dregistration/d5_Int_08_subLayers_0704.pt\"\n",
    "    tensors = convert_mat_v73_to_pt(src, dst)  # 모든 수치형 dataset 저장\n",
    "    print(f\"Saved {len(tensors)} tensors to {dst}\")\n",
    "    for k, v in tensors.items():\n",
    "        print(f\"- {k}: shape={tuple(v.shape)}, dtype={v.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 임의 z 단면: CAO 전/후(+volume) 시각화 유틸 (디바이스 정합 버전) ========\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from utils.utils import fft2c, _center_embed, load_layers,ifft2c, _center_crop\n",
    "\n",
    "\n",
    "def _amp_phase_np(t: torch.Tensor):\n",
    "    x = t.detach().cpu().numpy()\n",
    "    return np.abs(x), np.angle(x)\n",
    "\n",
    "def _soft_pupil(H: int, W: int, device, r0=0.98, feather=0.02):\n",
    "    yy = torch.linspace(-1, 1, H, device=device)\n",
    "    xx = torch.linspace(-1, 1, W, device=device)\n",
    "    Yg, Xg = torch.meshgrid(yy, xx, indexing='ij')\n",
    "    r = torch.sqrt(Xg*Xg + Yg*Yg)\n",
    "    return torch.clamp((1 - (r - r0)/feather), min=0.0, max=1.0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_cao_slice(z_idx: int):\n",
    "    assert 'img_vol' in globals(), \"img_vol (Z,X,Y) complex tensor가 필요합니다.\"\n",
    "    Z, X, Y = img_vol.shape\n",
    "    dev = img_vol.device\n",
    "    z = int(np.clip(z_idx, 0, Z-1))\n",
    "\n",
    "    # ---- 3D 임베드/크롭 헬퍼 ----\n",
    "    def _center_embed_hwz(x: torch.Tensor, out_hw):\n",
    "        X0, Y0, Zs = x.shape\n",
    "        H, W = out_hw\n",
    "        rs, cs = H//2 - X0//2, W//2 - Y0//2\n",
    "        out = torch.zeros((H, W, Zs), dtype=x.dtype, device=x.device)\n",
    "        out[rs:rs+X0, cs:cs+Y0, :] = x\n",
    "        return out, (rs, cs, X0, Y0)\n",
    "\n",
    "    def _center_crop_hwz(x: torch.Tensor, rs_cs_hw):\n",
    "        rs, cs, X0, Y0 = rs_cs_hw\n",
    "        return x[rs:rs+X0, cs:cs+Y0, :]\n",
    "\n",
    "    # ---- phase/filter 준비 (자가복구) ----\n",
    "    phase_fd_local = None\n",
    "    if 'phase_fd' in globals():\n",
    "        phase_fd_local = globals()['phase_fd']\n",
    "    elif ('A_AdamW' in globals()) and ('Zfd' in globals()):\n",
    "        phase_fd_local = torch.tensordot(Zfd, A_AdamW, dims=([2],[0]))  # (Hfd,Wfd)\n",
    "\n",
    "    CAOfilter_local = globals().get('CAOfilter', None)\n",
    "\n",
    "    if (phase_fd_local is None) and (CAOfilter_img_local is None):\n",
    "        raise RuntimeError(\"phase_fd / (A_AdamW+Zfd) / CAOfilter 중 하나가 필요합니다.\")\n",
    "\n",
    "    # 크기 파라미터\n",
    "    Him_local = int(globals().get('Him', X))\n",
    "    Wim_local = int(globals().get('Wim', Y))\n",
    "    if phase_fd_local is not None:\n",
    "        Hfd_local, Wfd_local = phase_fd_local.shape\n",
    "    else:\n",
    "        Hfd_local = int(globals().get('Hfd', Him_local))\n",
    "        Wfd_local = int(globals().get('Wfd', Wim_local))\n",
    "\n",
    "    # ---------- Before ----------\n",
    "    sl_before = img_vol[z]  # (X,Y) complex\n",
    "\n",
    "    # ---------- After (slice-only) ----------\n",
    "    if phase_fd_local is not None:\n",
    "        sl_embed, rs_cs_hw_local = _center_embed(sl_before, (Hfd_local, Wfd_local))\n",
    "        Fz = fft2c(sl_embed)\n",
    "        pupil_soft = _soft_pupil(Hfd_local, Wfd_local, sl_before.device)\n",
    "        # ↓ 디바이스/자료형 통일 + ones_like 사용\n",
    "        P_fd = torch.exp(-1j * phase_fd_local.to(device=sl_before.device, dtype=sl_before.dtype))\n",
    "        ones_fd = torch.ones_like(P_fd)\n",
    "        P_fd = (P_fd - ones_fd) * pupil_soft + ones_fd\n",
    "        cz_full = ifft2c(Fz * P_fd)\n",
    "        sl_after_slice = _center_crop(cz_full, (Him_local, Wim_local), rs_cs_hw_local)\n",
    "    else:\n",
    "        pupil_soft_img = _soft_pupil(Him_local, Wim_local, sl_before.device)\n",
    "        Cimg = CAOfilter_local.to(device=sl_before.device, dtype=sl_before.dtype)\n",
    "        ones_img = torch.ones_like(Cimg)\n",
    "        P_img = (Cimg - ones_img) * pupil_soft_img + ones_img\n",
    "        F_xy = torch.fft.fft2(sl_before)\n",
    "        sl_after_slice = torch.fft.ifft2(F_xy * P_img)\n",
    "\n",
    "    # ---------- After (volume-corrected) ----------\n",
    "    if 'corrected_vol' in globals():\n",
    "        sl_after_vol = corrected_vol[z]\n",
    "        vol_title_suffix = \" (from corrected_vol)\"\n",
    "    else:\n",
    "        assert 'ISOS' in globals() and 'RPE' in globals(), \"ISOS, RPE 전역이 필요합니다.\"\n",
    "        PRLstart = int(np.floor(np.nanmin(ISOS))); PRLstart = max(PRLstart, 0)\n",
    "        PRLend   = int(np.ceil (np.nanmax(RPE)));  PRLend   = min(PRLend, Z-1)\n",
    "        slab = img_vol[PRLstart:PRLend+1]                 # (Zs,X,Y)\n",
    "        slab_xy = slab.permute(1,2,0).contiguous()        # (X,Y,Zs)\n",
    "\n",
    "        if phase_fd_local is None:\n",
    "            sl_after_vol = sl_after_slice\n",
    "            vol_title_suffix = \" (slice-like; no phase_fd)\"\n",
    "        else:\n",
    "            slab_zp_hwz, rs_cs_hw2 = _center_embed_hwz(slab_xy, (Hfd_local, Wfd_local))\n",
    "            slab_zp_bhw = slab_zp_hwz.permute(2,0,1).contiguous()  # (Zs,Hfd,Wfd)\n",
    "            F_zp = fft2c(slab_zp_bhw)\n",
    "\n",
    "            pupil_soft = _soft_pupil(Hfd_local, Wfd_local, F_zp.device)\n",
    "            P_fd = torch.exp(-1j * phase_fd_local.to(device=F_zp.device, dtype=F_zp.dtype))\n",
    "            ones_fd = torch.ones_like(P_fd)\n",
    "            P_fd = ((P_fd - ones_fd) * pupil_soft + ones_fd).unsqueeze(0)  # (1,Hfd,Wfd)\n",
    "            F_corr = F_zp * P_fd\n",
    "\n",
    "            slab_corr_bhw = ifft2c(F_corr)                         # (Zs,Hfd,Wfd)\n",
    "            slab_corr_hwz = slab_corr_bhw.permute(1,2,0).contiguous()\n",
    "            slab_corr_xy  = _center_crop_hwz(slab_corr_hwz, rs_cs_hw2)\n",
    "\n",
    "            if PRLstart <= z <= PRLend:\n",
    "                sl_after_vol = slab_corr_xy[..., z-PRLstart]       # (X,Y)\n",
    "            else:\n",
    "                sl_after_vol = sl_before\n",
    "            vol_title_suffix = \" (simulated full-slab)\"\n",
    "\n",
    "    # ---------- 수치/시각화 ----------\n",
    "    def _H_shannon(t: torch.Tensor) -> float:\n",
    "        I = (t.real**2 + t.imag**2).clamp_min(0)\n",
    "        p = I / (I.sum() + 1e-12)\n",
    "        return float((-(p * (p + 1e-12).log())).sum().item())\n",
    "\n",
    "    amp_b = torch.abs(sl_before).cpu().numpy()\n",
    "    amp_s = torch.abs(sl_after_slice).cpu().numpy()\n",
    "    amp_v = torch.abs(sl_after_vol).cpu().numpy()\n",
    "\n",
    "    vmin = np.percentile(np.hstack([amp_b.ravel(), amp_s.ravel(), amp_v.ravel()]), 1)\n",
    "    vmax = np.percentile(np.hstack([amp_b.ravel(), amp_s.ravel(), amp_v.ravel()]), 99)\n",
    "\n",
    "    H_before = _H_shannon(sl_before)\n",
    "    H_slice  = _H_shannon(sl_after_slice)\n",
    "    H_vol    = _H_shannon(sl_after_vol)\n",
    "\n",
    "    Imax_b = float((sl_before.real**2 + sl_before.imag**2).max().item())\n",
    "    Imax_s = float((sl_after_slice.real**2 + sl_after_slice.imag**2).max().item())\n",
    "    Imax_v = float((sl_after_vol  .real**2 + sl_after_vol  .imag**2).max().item())\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.suptitle(\n",
    "        f\"CAO slice visualization @ z={z} | \"\n",
    "        f\"H_b={H_before:.4f}, H_s={H_slice:.4f}, H_v={H_vol:.4f} | \"\n",
    "        f\"peak gain s×{(Imax_s+1e-12)/(Imax_b+1e-12):.2f}, v×{(Imax_v+1e-12)/(Imax_b+1e-12):.2f}\"\n",
    "    )\n",
    "\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    im1 = ax1.imshow(amp_b, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(\"Amplitude (Before)\")\n",
    "    ax1.axis(\"off\"); plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    im2 = ax2.imshow(amp_s, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title(\"Amplitude (After CAO — slice-only)\")\n",
    "    ax2.axis(\"off\"); plt.colorbar(im2, ax=ax2, shrink=0.8)\n",
    "\n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "    im3 = ax3.imshow(amp_v, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "    ax3.set_title(f\"Amplitude (After CAO — volume){vol_title_suffix}\")\n",
    "    ax3.axis(\"off\"); plt.colorbar(im3, ax=ax3, shrink=0.8)\n",
    "\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'/home/work/OCT_DL/CDAC_OCT/CDAC_PYTHON/data/2_3Dregistration/d5_Int_04_CAO.pt 안에서 (Nz,Nx,Ny) 복소 텐서를 찾지 못했습니다. 저장 시 CAO 적용된 fringes를 그대로 포함시켜 주세요.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m k \u001b[38;5;241m=\u001b[39m _pick_fringes_key(d_cao)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCAO_PT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 안에서 (Nz,Nx,Ny) 복소 텐서를 찾지 못했습니다. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m저장 시 CAO 적용된 fringes를 그대로 포함시켜 주세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m fr_after \u001b[38;5;241m=\u001b[39m d_cao[k]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(fr_after) \u001b[38;5;129;01mor\u001b[39;00m fr_after\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '/home/work/OCT_DL/CDAC_OCT/CDAC_PYTHON/data/2_3Dregistration/d5_Int_04_CAO.pt 안에서 (Nz,Nx,Ny) 복소 텐서를 찾지 못했습니다. 저장 시 CAO 적용된 fringes를 그대로 포함시켜 주세요.'"
     ]
    }
   ],
   "source": [
    "# /scripts/bootstrap_visualize_cao_slice_from_fringes.py\n",
    "from __future__ import annotations\n",
    "# /scripts/bootstrap_visualize_cao_slice_from_fringes.py\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "ROOT = Path(\"/home/work/OCT_DL/CDAC_OCT/CDAC_PYTHON\")\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.utils import load_layers\n",
    "\n",
    "# 입력 경로\n",
    "CAO_PT       = ROOT / \"data/2_3Dregistration/d5_Int_04_CAO.pt\"          # (CAO 적용된 fringes 들어있음)\n",
    "RAW_FRINGES  = ROOT / \"cache/fringes.pt\"                                 # 원본 fringes (Before)\n",
    "LAYERS_PT    = ROOT / \"data/2_3Dregistration/d5_Int_08_Layers_0704.pt\"\n",
    "SUBLAYERS_PT = ROOT / \"data/2_3Dregistration/d5_Int_08_subLayers_0704.pt\"\n",
    "\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def _pick_fringes_key(d: dict) -> str | None:\n",
    "    # 3D 복소 텐서(Nz,Nx,Ny)인 키를 우선 탐색\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, torch.Tensor) and v.ndim == 3 and torch.is_complex(v):\n",
    "            return k\n",
    "    # fallback: 흔한 이름 힌트\n",
    "    for k in (\"fringes_cao\", \"fringes_after\", \"fringes\", \"F_after\", \"F\"):\n",
    "        if k in d and isinstance(d[k], torch.Tensor):\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "# --- Before: 원본 fringes → img_vol ---\n",
    "if not RAW_FRINGES.exists():\n",
    "    raise FileNotFoundError(f\"Not found: {RAW_FRINGES}\")\n",
    "fr_before = torch.load(str(RAW_FRINGES), map_location=\"cpu\")\n",
    "if not torch.is_complex(fr_before) or fr_before.ndim != 3:\n",
    "    raise TypeError(\"RAW fringes must be complex (Nz,Nx,Ny).\")\n",
    "globals()[\"img_vol\"] = torch.fft.ifft(fr_before, dim=0).to(dev)  # (Z,X,Y) complex\n",
    "\n",
    "# --- After: CAO 적용된 fringes → corrected_vol ---\n",
    "d_cao = torch.load(str(CAO_PT), map_location=\"cpu\")\n",
    "k = _pick_fringes_key(d_cao)\n",
    "if k is None:\n",
    "    raise KeyError(\n",
    "        f\"{CAO_PT} 안에서 (Nz,Nx,Ny) 복소 텐서를 찾지 못했습니다. \"\n",
    "        \"저장 시 CAO 적용된 fringes를 그대로 포함시켜 주세요.\"\n",
    "    )\n",
    "fr_after = d_cao[k]\n",
    "if not torch.is_complex(fr_after) or fr_after.ndim != 3:\n",
    "    raise TypeError(f\"'{k}' must be complex (Nz,Nx,Ny).\")\n",
    "globals()[\"corrected_vol\"] = torch.fft.ifft(fr_after, dim=0).to(dev)  # (Z,X,Y) complex\n",
    "\n",
    "# 크기/레이어\n",
    "Z, Him, Wim = globals()[\"img_vol\"].shape\n",
    "globals()[\"Him\"], globals()[\"Wim\"] = int(Him), int(Wim)\n",
    "\n",
    "sublayers_arg = SUBLAYERS_PT if SUBLAYERS_PT.exists() else None\n",
    "ILM, NFL, ISOS, RPE = load_layers(LAYERS_PT, sublayers_arg)\n",
    "globals()[\"ISOS\"] = np.asarray(ISOS, dtype=float)\n",
    "globals()[\"RPE\"]  = np.asarray(RPE,  dtype=float)\n",
    "\n",
    "# 플래그: 프리코렉티드 모드(phase/CAOfilter 재적용 금지)\n",
    "globals()[\"USE_PRECORRECTED\"] = True\n",
    "\n",
    "print(f\"[ready] img_vol={tuple(globals()['img_vol'].shape)}, \"\n",
    "      f\"corrected_vol={tuple(globals()['corrected_vol'].shape)}, \"\n",
    "      f\"Him×Wim=({globals()['Him']},{globals()['Wim']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
